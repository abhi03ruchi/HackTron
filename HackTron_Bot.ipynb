{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhi03ruchi/HackTron/blob/main/HackTron_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import string\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "y6iRM5epEUBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "csp4ei0UKrE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/BotDataset (2).txt','r',errors = 'ignore', encoding = 'utf-8')\n",
        "paragraph = f.read()\n",
        "paragraph"
      ],
      "metadata": {
        "id": "uH27KIpVEVCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "greetings = ['Hey', 'Hello', 'Hi', 'Itâ€™s great to see you', 'Nice to see you', 'Good to see you']\n",
        "bye = ['Bye', 'Bye-Bye', 'Goodbye', 'Have a good day','Stop']\n",
        "thank_you = ['Thanks', 'Thank you', 'Thanks a bunch', 'Thanks a lot.', 'Thank you very much', 'Thanks so much', 'Thank you so much']\n",
        "thank_response = ['You\\'re welcome.' , 'No problem.', 'No worries.', ' My pleasure.' , 'It was the least I could do.', 'Glad to help.']"
      ],
      "metadata": {
        "id": "_-KEcY9dEcSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')   # for first-time use only\n",
        "nltk.download('wordnet')    # for first-time use only\n",
        "\n",
        "\n",
        "sent_tokens = nltk.sent_tokenize(paragraph)\n",
        "word_tokens = nltk.word_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "EQvmUSGCElD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens[:1]"
      ],
      "metadata": {
        "id": "JZ_q-SJ7EolG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens[:7]"
      ],
      "metadata": {
        "id": "-JjorbOlEsRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmitization\n",
        "\n",
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]    # iterate through every token and lemmatize it\n",
        "# string.punctuation has all the punctuations\n",
        "# ord(punct) convert punctuation to its ASCII value\n",
        "# dict contains {ASCII: None} for punctuation mark\n",
        "\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "# remove_punct_dict\n",
        "# This will return the word to LemTokens after Word tokenize, lowering its case and removing punctuation mark\n",
        "# translate will find punctuation mark in remove_punct_dict and if found replace it with None\n",
        "\n",
        "def Normalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "id": "328O1vlzEv0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer   # For Tfid Vectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity   # For cosine similarity"
      ],
      "metadata": {
        "id": "0ol_vyn1E20V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "    robo_response = ''\n",
        "    \n",
        "    sent_tokens.append(user_response)   # Appending the Question user ask to sent_tokens to find the Tf-Idf and cosine_similarity between User query and the content.\n",
        "    TfidfVec = TfidfVectorizer(tokenizer = Normalize, stop_words='english')    #tokenizer ask about Pre-processing parameter and it will consume the Normalize() function and it will also remove StopWords\n",
        "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)    # It will do cosine_similarity between last vectors and all the vectors because last vector contain the User query\n",
        "    idx = vals.argsort()[0][-2]     # argsort() will sort the tf_idf in ascending order. [-2] means second last index i.e. index of second highest value after sorting the cosine_similarity. Index of last element is not taken as query is added at end and it will have the cosine_similarity with itself.\n",
        "\n",
        "    flat = vals.flatten()   # [[0,...,0.89,1]] -> [0,...,0.89,1] this will make a single list of vals which had list inside a list.\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]  # this contains tfid value of second highest cosine similarity\n",
        "\n",
        "    if(req_tfidf == 0):    # 0 means there is no similarity between the question and answer\n",
        "        robo_response = robo_response + \"I am sorry! I don't understand you. Please rephrase you query.\"\n",
        "        return robo_response\n",
        "    \n",
        "    else:\n",
        "        robo_response = robo_response + sent_tokens[idx]    # return the sentences at index -2 as answer\n",
        "        return robo_response"
      ],
      "metadata": {
        "id": "PYW1xiUqE9Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def bot_initialize(user_msg):\n",
        "    flag=True\n",
        "    while(flag==True):\n",
        "        user_response = user_msg\n",
        "        if(user_response not in bye):\n",
        "            if(user_response == '/start'):\n",
        "                bot_resp = \"\"\"Hi! There. I am your HackTron. I can solve all your doubts related to hackathons so feel free to ask :) . \\nType Bye to Exit.\"\"\" \n",
        "                return bot_resp\n",
        "            elif(user_response == '/stop'):\n",
        "                bot_resp= \"\"\"Bye Bye , hope I have solved all your Queries . \\nType /start or Hello to restart .\"\"\"\n",
        "                return bot_resp\n",
        "            elif(user_response in thank_you):\n",
        "                bot_resp = random.choice(thank_response)\n",
        "                return bot_resp\n",
        "            elif(user_response in greetings):\n",
        "                bot_resp = random.choice(greetings) + \", What information you what related to Hackathons \"\n",
        "                return bot_resp\n",
        "            else:\n",
        "                user_response = user_response.lower()\n",
        "                bot_resp = response(user_response)\n",
        "                sent_tokens.remove(user_response)   # remove user question from sent_token that we added in sent_token in response() to find the Tf-Idf and cosine_similarity\n",
        "                return bot_resp\n",
        "        else:\n",
        "            flag = False\n",
        "            bot_resp = random.choice(bye)\n",
        "            return bot_resp\n"
      ],
      "metadata": {
        "id": "PUwTIJd4FALq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "class telegram_bot():\n",
        "    def __init__(self):\n",
        "        self.token = \"6054228918:AAFEspN8DxQhBNqszmZB9Y8XxLacCuypXU4\"    #write your token here!\n",
        "        self.url = f\"https://api.telegram.org/bot{self.token}\"\n",
        "\n",
        "    def get_updates(self,offset=None):\n",
        "        url = self.url+\"/getUpdates?timeout=100\"   # In 100 seconds if user input query then process that, use it as the read timeout from the server\n",
        "        if offset:\n",
        "            url = url+f\"&offset={offset+1}\"\n",
        "        url_info = requests.get(url)\n",
        "        return json.loads(url_info.content)\n",
        "\n",
        "    def send_message(self,msg,chat_id):\n",
        "        url = self.url + f\"/sendMessage?chat_id={chat_id}&text={msg}\"\n",
        "        if msg is not None:\n",
        "            requests.get(url)\n",
        "\n",
        "    def grab_token(self):\n",
        "        return tokens"
      ],
      "metadata": {
        "id": "4fjT1D-fFFJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tbot = telegram_bot()\n",
        "\n",
        "update_id = None\n",
        "\n",
        "def make_reply(msg):     # user input will go here\n",
        "  \n",
        "    if msg is not None:\n",
        "        reply = bot_initialize(msg)     # user input will start processing from bot_initialize function\n",
        "    return reply\n",
        "       \n",
        "while True:\n",
        "    print(\"...\")\n",
        "    updates = tbot.get_updates(offset=update_id)\n",
        "    updates = updates['result']\n",
        "    print(updates)\n",
        "    if updates:\n",
        "        for item in updates:\n",
        "            update_id = item[\"update_id\"]\n",
        "            print(update_id)\n",
        "            try:\n",
        "                message = item[\"message\"][\"text\"]\n",
        "                print(message)\n",
        "            except:\n",
        "                message = None\n",
        "            from_ = item[\"message\"][\"from\"][\"id\"]\n",
        "            print(from_)\n",
        "\n",
        "            reply = make_reply(message)\n",
        "            tbot.send_message(reply,from_)\n"
      ],
      "metadata": {
        "id": "-TvLuwxEFRWF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}